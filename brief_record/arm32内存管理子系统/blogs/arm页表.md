# arm 页表的硬件实现

在 MMU 出现之前，操作系统中的内存管理相对简单很多，开发者所操作的都是看得见摸得着的物理内存，内存的管理工作相对简单且容易理解，但是直接物理内存的管理总会带来各种各样的问题，比如安全问题，而且程序数据和硬盘上的普通文件数据并不一样，对内存地址有相当的依赖性，这也决定了让开发者直接操作物理地址是非常不方便，甚至是不合理的。

不知道你有没有听过这名言：

```
计算机科学领域的任何问题都可以通过增加一个间接的中间层来解决。
```

这句话几乎概括了计算机软件体系结构的设计要点.整个体系从上到下都是按照严格的层级结构设计的.

CPU 中的 MMU 就是引入的这个中间层，提供一种新的虚拟地址的概念，开发者面对的是虚拟地址，而 MMU 负责将虚拟地址转换为对应的物理地址，中间提供一层映射。 

引入虚拟地址最大的意义在于：开发者所操作的地址不再受到任何限制，不需要像使用物理内存那样考虑该地址上是否存在真实的物理内存，该地址是否已经被占用，只需要对 MMU 负责，而不需要对物理内存负责，这就提供了很大的操作空间。

一方面，开发者可以很方便地开发出可移植的程序，毕竟 MMU 可以确保程序所占用的虚拟内存的分配，另一方面，由于虚拟内存到物理内存映射的建立是自由的，开发者不能直接访问真实的物理内存，这也大大提高了安全性。



## arm 中的 MMU 

在 arm  中，MMU 是处理器内部的硬件资源，不像串口、USB 等硬件控制器是 SOC 厂商添加的，因此 MMU 的访问并不是以外设寄存器的方式，而是由处理器内部集成的 cp15 协处理器进行管理。

上文中提到，MMU 对外提供虚拟地址，并维护虚拟地址到物理地址的映射，那么 MMU 到底是如何工作的呢？

要了解这个，首先得知道一个概念：页表，这是内存管理中的核心概念。

简单来说：实际的应用中，物理内存通常是比较大的，比如一块 2G 的内存，也就是一片 2\*1024\*1024\*1024 个字节的内存区域，要把它用起来，自然就需要对它进行管理，通常是以 4K 的粒度来分割内存，每 4K 一个页面，这时候 2G 的物理内存在系统中就被分成了 1M 个页面。

至于为什么操作系统要以 4K 一个页面来管理内存，而不是使用更大或者更小的粒度进行管理，这是在内存利用效率和管理成本之间做权衡取舍的结果。

每个页面都需要在操作系统中进行记录，毕竟你要使用它，必须得知道它的起始地址、大小、是否已经被分配等信息，而记录每个页面的相关信息也需要内存，这就是管理成本。同时，既然操作系统是按照页面进行记录的，那么在使用内存时也是以页面为单位，但是实际的内存使用中并不会刚好用完一个页面，可能只有 2/3 页，默认情况下，剩下的 1/3 也就被浪费了，这就是内存的利用率。那么，那剩下的 1/3 是不是可以继续使用呢，当然也是可以的，但是操作系统又得花一些内存去记录那 1/3 内存的起始地址以及使用的相关信息，又增加了管理成本。 

不难得出，页面划分的粒度越小，所浪费的内存是越少，管理成本越高，划分粒度越大，可能浪费的内存越多，管理成本越低。 

这就像你新写了一本书，如果章节索引划分得很细，那么用户在读书的时候就可以很方便地根据章节目录找到自己想找的内容，但同时也意味着你的目录也会占用大量的页面，我想你肯定没见过半本目录半本内容的书吧。如果章节划分得很粗，目录所占用的页面较少，但是用户想找一个具体的内容又不太方便。 

上面所讨论的是物理内存和分页的概念，回过头来再看看，页表到底是什么？

MMU 提供虚拟地址空间，虚拟地址空间的大小等于 CPU 的线性地址宽度，32 位系统中默认是 4G，**页表其实就是一张映射表，主要记录了虚拟地址和物理地址之间的映射关系**，也就是说，当程序访问一个虚拟地址时，其对应的物理地址就是通过查找页表来找到的。  

**需要特别注意的是，页表并不是由 MMU 来建立，而是由操作系统建立，建立一个页表的流程通常为：**

* 程序因为某些原因需要申请一片内存，调用内核提供的申请页面接口
* 内核从物理内存中找到合适的物理页面以及其对应的虚拟页面
* 建立该物理页面到虚拟页面的映射表，并把这个映射表信息提交给 MMU
* 返回虚拟页面地址给申请者
* 申请者下次使用该段内存时，使用的是虚拟页面地址，MMU 通过查页表获取对应的物理地址，然后根据需求读写该段内存上的值

从这个过程可以看出，MMU 的作用只是维护页表，并提供页表的操作接口，毕竟物理内存和虚拟内存空间都还是得由操作系统来管理。

MMU 最主要的作用是维护页表，并将输入的虚拟地址访问转换为物理地址访问，同时还支持访问属性的控制，防止非法访问，向 CPU 报告异常。 



## 多级页表

对于 linux 这种支持多进程的操作系统，进程之间地址隔离的特性让每个进程看起来都拥有独立的 4G 地址空间，实际上不能算是 4G，内核部分是共享的，通常 3G~4G 地址空间是内核空间，因此，一个用户进程占用了独立的 0~3G 的内存空间。

也就是说，对于每个进程而言，虚拟地址对于物理地址的映射都是独立的，从而每个进程都需要一个独立的页表。 

让我们来计算一下，一个完整的页表需要多少项，计算过程很简单：4G / 4K = 1M，也就是一共有 1M 个页面，这些页面如何访问呢？

![](4K单层映射下的虚拟地址到物理地址转换.jpg)

将开发者需要访问的虚拟地址的前 20 位作为页面偏移，该偏移值上保存的是对应的物理页面地址，占用 4 字节，20 位刚好对应 1M 空间，后 12 位用于页内偏移，索引到具体的物理页面上的内存字节，这样就根据虚拟地址查找到了对应的物理地址。 

也就是说，每个虚拟地址到物理页面的映射占用 4 bytes，那么一个完整的页表就需要 4M 字节，注意，因为每个进程是独立的，因此系统中每存在一个进程，就需要额外地为每个进程申请 4M 的内存空间，一个系统中存在 50 个进程并不夸张，仅仅是为每个进程分配页表，就要占用掉 200M 空间，这明显是非常不划算的。

同时，如果刚开始运行时申请 4M 内存不在话下，一旦内存中碎片多了，那么申请连续的 4M 空间是非常吃力的，为什么页表需要连续的空间呢？上文中有说到，页表的查找实际上是 MMU 执行的，软件只是将页表基地址交给 MMU，MMU 不能接受不连续的地址，这是硬件决定的。

解决这个问题的办法是使用多级页表，处理器是否支持多级页表以及支持页表的级数也是由硬件决定的，arm32 硬件上最多支持二级页表，也就是支持使用一级或者二级页表，主要使用二级页表。

多级页表有什么好处呢？

在二级页表的结构中，第一级的页表的内容不再指向具体的物理页面，而是指向第二级页表的地址，而第二级页表的内容指向具体的物理页面，以此索引到具体的物理地址。

二级页表虚拟地址到物理地址的映射可以参考下图：

![](4K二级页表.jpg)

通用的二级页表映射中，每个页面的 size 依旧是 4K，32 位的虚拟地址被解析为三个部分，首先，一级页表的基地址被传递给 MMU，当程序发起一个虚拟地址的访问时。

一级页表一共 4096 项，MMU 取出虚拟地址的前 12 bits * 4，就可以根据地址索引找到一级页表中对应的项，该项中保存的是二级页表的地址。

二级页表一共 256 项，MMU 取出虚拟地址的中间 8 bits * 4，就可以根据地址索引找到二级页表中对应的项，该项中保存的是物理页面的基地址。

知道了物理页面的基地址，MMU 再取出虚拟地址的最后 12 bits，作为物理页的页内偏移，寻址到具体的内存地址。   

在上述这种二级页表的结构中，MMU 并不要求一级页表和二级页表存储在连续的地址上，这并不难理解，对于硬件来说，在查表时，只需要提供给 MMU 目标范围内的数据即可，比如在第一级查完之后，可以确定目标物理面落在了 0x00100000~0x001fffff 地址之间，那么内核只需要进一步提供这个区间的映射表即可。 

因此一级页表需要占用连续的 4096*4=16K 内存，而二级页表一共 4096 个，每个占用连续的 1K 字节，MMU 不要求所有二级页表保存在连续的地址上。

显而易见，页表的存储不再需要连续且大量的物理地址，这对新进程的创建时比较友好的，毕竟大片内存的申请随着系统的运行越来越难以得到。

另一个巨大的好处在于，大部分程序并不会使用所有的虚拟地址，往往只是其中的一小部分，这种情况下，二级页表完全可以做到按需分配，用到哪一部分的虚拟地址，就创建对应的二级页表，完全没必要将所有 4096 个二级页表一次性创建，二级页表相比于一级页表拥有更好的扩展性。 

采用二级页表的方案极大地解决了内存利用效率的问题，既然多级页表这么好用，那何不继而采用三级、四级页表呢？

实际上，在 arm32 扩展内存中，使用了三级页表，因为随着物理内存的增大，增加页表的级数可以节省页表空间，原理和上述一致，而 arm64 中支持 4 级页表，linux 因为要支持所有体系架构，软件上采用 5 级页表。

但是，从上文中虚拟地址到物理地址的转换中应该不难发现，采用多级页表的副作用是非常明显的，采用二级页表将导致访问一个虚拟地址需要经过两次内存访问，第一次访问到二级页表，第二次才能访问到真正的内存，多级页表的访问次数也是线性增加，尽管处理器中的缓存器件可以缓解这个问题，但是随着页表级数的增加，内存访问时间延长是必然的。 



## arm 中页表的硬件特性

页表实际上是硬件和软件合作的产物，



硬件上支持怎么分页，4K 和 1M 映射介绍

如何访问一个虚拟地址



