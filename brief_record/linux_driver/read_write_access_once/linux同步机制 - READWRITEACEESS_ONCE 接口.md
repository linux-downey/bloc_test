# linux同步机制 - READ/WRITE/ACEESS_ONCE 接口
在阅读内核代码的过程中，如果你不断地深挖某个模块的实现，通常会遇到 READ_ONCE 或者 ACEESS_ONCE 这一类接口，对于梳理模块的框架结构来说，并不需要详细地了解这几个宏的定义，只需要知道如何使用就好。

READ_ONCE 的作用就是读出某个变量，val = READ_ONCE(global_val) 可以简单地理解成 val = global_val，同样的，对于 WRITE_ONCE 和 ACEESS_ONCE 也是同样的效果，使用这种宏看起来是多此一举。

但是，既然存在就有它存在的理由，只是 linux 内核提供的接口屏蔽了实现细节，我们只需要知道怎么用就 OK，当看到这一系列 \*\_ONCE 接口时，有个模糊的概念：这些接口是为了解决一些同步问题而出现，因此在使用的时候，为了保险起见，大可以对所有全局对象内存读写操作都添加上这个接口，在没有详细了解 \*\_ONCE 的实现时，这种做法是比较保险的，可能会损失一些性能，而大部分情况下，这些性能损失和潜在的 bug 比起来不值一提。

不过，内核操作是严谨的，在编写内核代码时需要清晰地知道我们正在做的事，所以越是这种基础的、常用的接口，越是需要弄清楚底层细节。



## volatile
嵌入式工程师对 volatile 这个关键词一定不会陌生，经常会在各种嵌入式程序中见到它的身影。   

程序的运行并不会严格地按照程序的设计逻辑执行，应用程序需要通过编译器将这些程序转化为机器代码，同时这些二进制的机器码在 CPU 上运行，由 CPU 决定执行路径。如果编译器仅仅是简单地对程序进行翻译，CPU 仅仅是按照二进制代码逐条执行，事情并不会多复杂。实际上，编译器以及 CPU 的设计人员对程序执行效率有非常疯狂地执着，丝毫不会放过任何一个可以让程序运行更快的机会。  

对于编译过程而言，编译器并不完全相信程序员，而是自主地对程序员开发的程序进行优化，这种优化通常可以带来更好地性能，比如自动检测并删除冗余的部分以节省空间、或者用更有效率的指令替换那些低效的操作(比如将 i*8 换成 i<<3)，或者对不相关的指令进行重新排序以加速程序的执行，程序员普遍可以接受这种优化，因为编译器的优化通常确实可以提高执行效率以及节省内存空间。   

但是，要命的是，编译器优化只保证单线程下的安全，也就是这种优化并不考虑多线程的情况，而且编译器标准也默许了这种行为(毕竟这种优化所带来的执行效率提升非常可观)，这就导致了在多线程或者多核的情况下，共享对象的操作变成了一件非常危险的事，多个执行流同时对一个共享对象的操作往往会带来一些意向不到的 bug。  

相对于编译器开发人员对执行效率的执着，CPU 的设计人员可谓是有过之而无不及，同样的，他们也不会放过任何一个可以加速 CPU 执行指令的机会，每个 CPU 中都包含各种各样的逻辑电路，以实现各种各样的功能，比如数据计算、数据传输。

CPU 总是任劳任怨地逐条执行二进制代码中的指令，执行到指定的功能就会调用到对应的电路进行工作，而没有使用到的电路则不工作，这种资源的闲置自然是 CPU 设计人员不可接受的，因此在单指令顺序执行的基础上发展出了流水线技术，多级流水线共同工作以达到并行执行的效果，也就在同一时刻调用更多的电路，同时也加速了程序的执行。  

流水线技术的普及的同时，设计人员发现 CPU 各指令之间的执行速度不同也会导致一些问题，如果两条指令存在依赖关系，比如数据依赖或者控制依赖，后一条指令就必须等到前一条指令执行完成之后，才能开始，指令流水线会因此遭受延迟，为了解决这个问题，CPU 设计人员对执行的指令进行重排，比如在 B 依赖 A 时，A 同时是一个耗时操作，就可以将与 A、B 不相关的指令 C 挪到 A 后加入到流水线，而 B 则放到后面，反正它要等 A 执行完成。这种流水线技术搭配指令重排所带来的效率提升是非常可观的。  

和编译器优化一样，这种指令重排的优化并不是免费的午餐，正如上文提到的，CPU 会将没有依赖关系的指令进行重排，在单核中，这并没有什么问题，但是在多核下，问题就来了，两个进(线)程分别运行在两个核上，假设执行下列的指令：

    { A == 1; B == 2 }
    CPU1        CPU2
    A = 3;		x = B;
    B = 4;		y = A;
 

因为指令的重排，最后的执行结果存在四种可能的结果：

    x == 2， y == 1
    x == 2， y == 3
    x == 4， y == 1
    x == 4， y == 3

尽管无论在 CPU1 还是在 CPU2 上， A、B，x、y 并没有任何逻辑上的联系，但是当两个 CPU 上的程序同时执行时，还是会造成错误的结果。   

编译器假设程序只运行在单线程中，而 CPU 假设系统中只有一个 CPU，当这种假设不成立的时候，问题就发生了。对于编译器来说，解决方法通常是 volatile 关键字，该关键字是针对编译器的，使用该关键字声明的对象相当于人为地通知编译器不要尝试对该对象进行任何优化，对于全局的共享对象，使用该关键字就可以解决编译器优化带来的问题。  

而对于多核下的 CPU 指令重排所带来的问题，解决方法就是内存屏障，内存屏障是针对 CPU 的一种标准，具体的实现与架构相关，该指令保证：以内存屏障指令为界，屏障前的所有指令一定会在屏障后的指令之前执行，也就是指令重排不会跨过这道屏障，也就解决了指令重排的问题。   

**同时，需要注意的是：所有的 CPU 内存屏障封装都隐式地包含了编译器屏障(同时阻止编译乱序)**。  



## 内核中 volatile 的使用
**尽管在嵌入式领域，volatile 关键词在共享数据同步中扮演着非常重要的角色，经常被提起或者使用，但是在 linux 内核中，你不应该去主动地去使用 volatile 这个关键词，内核维护者甚至认为：如果你迫不得已在你的代码中需要使用 volatile 来实现数据同步，那么你的代码肯定是哪里出了 bug。至于具体的原因，下面继续讨论。**  

在很多资料以及博客中，讲解 volatile 的示例大多都是：因为寄存器缓存数据导致数据同步出错(网上有很多关于 volatile 的讲解，这里不展开)，以至于很多朋友都将 volatile 理解为：volatile 关键字的作用就是保证在读写内存的时候直接从内存读取，而不是从备份的缓存中读取。

这个概念并不是错的，但是并不全面，本质上 volatile 的作用是拒绝编译器的激进优化措施( aggressive optimization)，而并不只是针对直接读取内存这一个方面，激进优化措施指的是什么呢？

假设有两条连续的 (i +=1)，在优化等级 O=2 时编译器会将其优化为一条指令 (i+=2)，这就属于激进的优化，无论怎么看，将两条指令合并为一条指令明显就没有考虑到并发的情况，这就属于激进的优化策略。相对应的，比如 (i*8) 这条指令，编译器会将其替换为 (i<<3)，这在任何优化情况下都是没有问题的，这就属于非激进的优化，即使使用 volatile，这一类优化还是会执行。  

不难想到，编译器的优化带来大幅度的性能提升，而拒绝编译器的优化自然会带来一些性能上的损失，或许可以想一想，我们真的有必要让某个使用 volatile 前缀的全局变量在整个生命周期内都拒绝这种优化吗，还是有其它提高效率的办法？  

毫无疑问， volatile 针对的是共享的全局数据，而共享的全局数据操作通常都会需要同步原语进行保护，比如 spinlock、mutexlock、Memory barrier 等，这些同步原语本身就包含了针对编译器的优化，如果它们被正确地使用，完全没有必要再去使用 volatile，在这种情况下，将共享数据声明为 volatile 类型是没有必要的，只会降低执行速率(因为所有声明为 volatile 的类型都不会进行优化)。  

看下面的示例：

```c++
spin_lock(&the_lock);
do_something_on(&shared_data);
do_something_else_with(&shared_data);
spin_unlock(&the_lock);
```
如果所有的代码都正确地使用 spinlock，那么这段代码中的 shared_data 就不会被其它执行流修改，其它任何尝试获取锁的指令流都将等待这段代码执行完成，所以并不需要考虑，同时在 spin_unlock 中，将会使用到 Memory barrier 指令，这个指令隐式地抑制了编译器的优化，CPU 会将相关的缓存信息全部丢弃，也就不存在数据缓存导致的同步问题，对于其它的同步原语也是同样的结果。  

如果 shared_data 使用 volatile 进行修饰，spinlock 或者其它的同步机制依旧需要，此时编译器对 shared_data 的优化都不会存在，事实上这是没有必要的，被锁保护的共享数据操作是可以接受适当的优化的，因为锁内的临界区已经完全可以保证数据不会出现同步问题。  

实际上，内核维护者不建议开发者使用 volatile，并不代表内核中不存在 volatile 的使用，在内核的这些情况下，依旧使用到 volatile：



* 内联汇编的代码中会使用到。
* linux 中 jiffies 变量，jiffies 变量的特殊之处在于，每次引用时它可以具有不同的值，但是无需任何特殊锁定即可读取它。因此jiffies 可能是不稳定的，但是强烈反对添加此类其他变量。就连 linus 也称之为"stupid legacy"。
* 指向一致性内存中可能由 I/O 设备修改的数据结构的指针有时可能会易失，这种情况的一个示例是网络适配器使用的环形缓冲区。

另一种情况是：对于那么不需要同步原语提供保护的访问操作而言，看起来也需要 volatile 进行声明，比如对全局对象的读和直接设置，实际上，为了避免 volatile 的直接使用，内核提供了相应的接口:READ_ONCE 和 WRITE_ONCE.，这也是本章讨论的主角。   



## READ_ONCE 和 WRITE_ONCE
READ_ONCE 和 WRITE_ONCE 的接口形式如下：

```c++
READ_ONCE(x)   // 从内存中读取 x 的值并返回

WRITE_ONCE(x， val)  //将 val 的值写到 x 对应的内存中
```

从最终的结果来看，READ_ONCE 和 WRITE_ONCE 并不做什么事，它们的作用正如上文中提到的：作为将 x 直接声明为 volatile 的替代方案，来抑制编译器的优化。  

对于 从内存读 和 直接设置内存 这两个操作而言，并不需要锁机制(或者原子操作)的保护，这也不难理解，当多个执行流同时读一个共享内存时，所读到的数据没有出错的可能。而对于设置内存而言，可以简单地理解为就是一条 str 指令，而单条内存写指令并不会产生同步问题。  



## 实现
既然聊到了这两个函数，就有必要看看这两个宏的具体实现，这是阅读内核代码的一个不错的习惯。  

READ_ONCE:

```c++
#define READ_ONCE(x) __READ_ONCE(x， 1)

#define __READ_ONCE(x， check)						\
({									\
	union { typeof(x) __val; char __c[1]; } __u;			\
	if (check)							\
		__read_once_size(&(x)， __u.__c， sizeof(x));		\
	else								\
		__read_once_size_nocheck(&(x)， __u.__c， sizeof(x));	\
	smp_read_barrier_depends(); /* Enforce dependency ordering from x */ \
	__u.__val;							\
})

static __always_inline
void __read_once_size(const volatile void *p， void *res， int size)
{
	__READ_ONCE_SIZE;
}

static __no_sanitize_address __maybe_unused
void __read_once_size_nocheck(const volatile void *p， void *res， int size)
{
	__READ_ONCE_SIZE;
}

#define __READ_ONCE_SIZE						\
({									\
	switch (size) {							\
	case 1: *(__u8 *)res = *(volatile __u8 *)p; break;		\
	case 2: *(__u16 *)res = *(volatile __u16 *)p; break;		\
	case 4: *(__u32 *)res = *(volatile __u32 *)p; break;		\
	case 8: *(__u64 *)res = *(volatile __u64 *)p; break;		\
	default:							\
		barrier();						\
		__builtin_memcpy((void *)res， (const void *)p， size);	\
		barrier();						\
	}								\
})
```
READ_ONCE 的源代码实现还是比较简单的，比较巧妙的是：在读取数据的时候，使用一个联合体来获取数据，因为数据的拷贝需要使用到指针，在联合体中定义一个 1 长度数组就可以用来代替该联合体的指针，这样的意义在哪儿呢？看起来我们可以直接使用 typeof(x) \_\_val，然后传入 &\_\_val 即可。  

在一种特殊的情况下，是不能直接使用 &\_\_val 的，也就是当 READ_ONCE 传入的数据类型为 const 前缀类型时，在对 const 类型的数据进行操作时，编译器会报错或者是警告，所以使用 union+1字节数组 的技巧来规避这种情况。  

在执行 \_\_READ_ONCE 读数据的时候，传入的另一个参数是 check，这个参数主要是针对内存的检查，如果没有指定 check，就会执行 \_\_read_once_size_nocheck，而该函数被 \_\_no_sanitize_address 前缀所标记，这个前缀是 gcc 的扩展实现，对应\_\_attribute__((no_sanitize_address))，以免去内存检查的步骤，其它的实现都是一样的。如果你对这部分感兴趣的话可以 google gcc 的 \_\_attribute\_\_ 扩展语法。 

在随后的源代码 \_\_read_once_size(或\_\_read_once_size_nocheck) 中，实现比较简单，就是实现内存拷贝，通过指定 volatile 属性的方式来阻止编译器的优化，以确保每次操作都是直接操作到内存，如果是操作超过 8 字节的内存，则需要添加内存屏障，再执行拷贝任务，内存屏障同时阻止编译器优化和 CPU 的乱序优化。  

可能有的朋友就有疑惑了，linux 内核维护者都说了不要使用 volatile，为什么这么还要使用到 volatile 呢？需要注意的是，这里的 volatile 的使用只是针对一个临时变量(\_\_val)，你也可以简单地理解成为目标变量赋予临时的 volatile 属性，以防止编译器的优化，而内核中不建议的是直接将全局变量声明为 volatile (局部变量也没有必要声明为 volatile)。   

WRITE_ONCE 和 READ_ONCE 的实现差不太多，各位可以自行阅读相关源代码。  

## 小结


* 在内核中编写代码时，不要声明全局对象为 volatile，这种行为并不会导致明显的错误，但更像是一个不那么优雅的一刀切行为，volatile 让整个对象都与编译器优化无缘，这会降低执行效率。  
* 正确地使用内核提供的同步机制是避免使用 volatile 的基础，同步机制中通常会包含阻止编译器优化的指令。  
* 在某些情况下，对全局对象的访问并不需要使用同步机制(spinlock、Memory barrier等)，看起来好像只能使用 volatile 了，针对这一情况，内核推出了 READ_ONCE 和 WRITE_ONCE，这两个宏的作用就很明显了。你也可以直接简单地记成：READ_ONCE/WRITE_ONCE 就是将操作对象 "临时 volatile 化" 的两个宏。  



### 参考

4.9.88 源码

https://www.kernel.org/doc/html/v4.10/process/volatile-considered-harmful.html
https://zhuanlan.zhihu.com/p/102406978
https://zhuanlan.zhihu.com/p/102370222

---

[专栏首页(博客索引)](https://zhuanlan.zhihu.com/p/362640343)

原创博客，转载请注明出处。






