# linux 网络驱动程序-驱动接收数据
上一章中讨论了设备驱动程序的初始化和数据发送，这一章我们继续讲解另一个核心的部分，数据的接收。  

## 接收处理程序
网卡的数据接收是基于中断的，也就是说，每当网卡从网口接收到网络上的数据时，就会触发一次中断，进入到网卡的中断处理程序中，网络上数据的发送和接收是这样的：

TODO.

为了能清晰地呈现数据在源/目标主机之间的流通，该图并没有考虑交换机和路由器等中间节点。  

从图中可以清晰的看到，发送端的应用数据经过一层层的封装，由物理层发出，经过传输介质，到达接收主机，所以，接收主机接收到的数据包是一个完整的网络数据包，包含网络所有层的协议数据信息。整个 linux 网络协议栈要做的就是再一层层地对这个包进行解析，最后获取到应用数据。   

我们讨论的是网卡的驱动程序，所以对于链路层网上的处理方式不做研究，只需要关注两个部分：
* 如何接收数据。
* 网卡所在的数据链路层如何处理数据并往上层传。


## 如何接收数据
数据从网口接收，经由物理层传递到网卡，一般情况下，网卡接收到数据并产生一个中断，因为网卡可以产生多个事件，最基本的两个中断是发送完成中断和接收中断，多个中断可能共用一根中断线，也就是只在内核中注册一个中断处理函数，中断产生之后再通过网卡的寄存器查询产生的中断类型。  

也有可能在内核中占用多根中断线，驱动中注册多个中断处理函数，这完全取决于硬件的设计。  

比较常见的网卡 dm9000 有两个中断，一个 WOL 中断，一个是数据中断，所以需要在驱动中调用两次 request_irq 来注册两个中断的处理。  

其中 WOL 全称为 wakeup on line，即远程唤醒功能，通过网络数据包唤醒睡眠的主机。dm9000 的数据中断包括接收中断、发送完成中断等，当中断触发进入中断服务子程序时，需要通过查询网卡的中断状态寄存器来确定发生的中断类型，以进入不同的处理流程。  

当接收到数据时，产生中断，中断处理程序可以简单地从网卡数据寄存器中读出接收的数据，然后在内存中处理，也可以使用 dma 的方式进行数据接收。  

### NAPI
大多数的经典网卡的实现都是基于中断的形式，每接收一次数据进入一次中断处理程序，当网络流量非常大，比如传输一个很大的文件的时候，网卡将会产生大量的中断的请求，每次中断的执行都代表着执行流的切换，大量的中断将会占用非常多的 CPU 资源。  

于是，轮询的方式被提出，在软件的世界中，轮询这个策略总是被扣上一个低效率的帽子，因为它的策略就是原地等待，但是在一些特殊的场景，它又是比较好的解决方案，比如内核中自旋锁的实现，在确定等待时间的开销小于中断的开销时，是可以使用轮询的。  

当然，这里的轮询并不是简单的将网卡数据接收设置为查询，而是采用中断和轮询结合的方式：当接收中断被触发的时候，在中断处理程序中关闭当前接收中断，使用轮询的机制不断地查询网卡的下一包数据，在接收非常大的网络流量时，轮询可以明显节省 CPU 的开销。  

这种 中断+轮询 的接收机制在内核中有相应的支持，这一套接口被命名为 NAPI，接口的框架细节在这一章中不做详细讨论。  

那么，如何判断何时该进入轮询？何时使用纯中断接收？在进入轮询之后何时恢复中断呢？  

这些问题并不存在标准的答案，在内核中，这是一种策略，至于具体的实现需要根据实际情况灵活使用。  


## 处理流程
处理流程也就是我们上述提到的第二个问题：网卡所在的数据链路层如何处理数据并往上层传。

在这一阶段基于的假设是已经接收到了一个数据包，不管是中断方式的接收，还是 dma 的接收方式。

我们来看看中断处理程序中是如何处理的：

* 创建 sk buff 结构，并将接收到的网络数据放置到 sk buff 中
* 按照链路层的协议解析数据包，提取协议字段，确定上层协议类型
* 将数据提交到上层


### 创建 sk_buff
在上一节中我们了解到：所有网络数据包的接收和发送处理都基于 sk_buff 结构，所以，当我们接收到一个完整的数据包时，需要将数据放到一个 sk_buff 结构中，这片内存需要向内核申请：

```
struct sk_buff *netdev_alloc_skb(struct net_device *dev, unsigned int len,gfp_t gfp_mask)
```
该接口通过 kmem_cache_alloc 向内核缓存申请一片内存，可以通过 gfp_mask 掩码来指定内存申请的 flag。 

严格地来说 sk buff 算是一片格式化的内存，kmem cache 机制是针对特定申请/释放非常频繁的设备，产生一片专用的内存区域，在释放的过程中并不是真正地释放，而是缓存下来等待下一次的申请。使用 kmem_cache_alloc 申请的内存虽然没有特定的划分，但是该片内存中的数据格式就是按照 sk buff 的格式存在的。  

完成 sk buff 的申请之后，接下来将接收到的数据 copy 到 sk buff 中，使用 memcpy 接口即可，将数据 copy 到 skb->data 部分。  

### 协议解析
严格来说其实并没有协议解析的工作，而是调用内核的接口获取协议类型：

```
__be16 eth_type_trans(struct sk_buff *skb, struct net_device *dev);
```

返回值是协议类型，源码实现：

```
__be16 eth_type_trans(struct sk_buff *skb, struct net_device *dev)
{
	unsigned short _service_access_point;
	const unsigned short *sap;
	const struct ethhdr *eth;

	skb->dev = dev;
    //reset mac 地址
	skb_reset_mac_header(skb);

    //获取 skb 中 data 指针
	eth = (struct ethhdr *)skb->data;
	skb_pull_inline(skb, ETH_HLEN);

    //通过目的 mac 确定数据包是不是给本机的
	if (unlikely(is_multicast_ether_addr_64bits(eth->h_dest))) {
		if (ether_addr_equal_64bits(eth->h_dest, dev->broadcast))
			skb->pkt_type = PACKET_BROADCAST;
		else
			skb->pkt_type = PACKET_MULTICAST;
	}
	else if (unlikely(!ether_addr_equal_64bits(eth->h_dest,
						   dev->dev_addr)))
		skb->pkt_type = PACKET_OTHERHOST;

    //确定数据包的上层协议类型，通常是 ETH_P_IP,表示 IP 层。
	if (likely(eth_proto_is_802_3(eth->h_proto)))
		return eth->h_proto;

	sap = skb_header_pointer(skb, 0, sizeof(*sap), &_service_access_point);
	if (sap && *sap == 0xFFFF)
		return htons(ETH_P_802_3);

	return htons(ETH_P_802_2);
}
```
eth_type_trans 接收两个参数，skb 和 netdev,这两个参数就不再过多介绍，返回协议的 protocol，通常的调用方式为：



在该函数中，通过解析数据包中链路层协议字段，主要是做两件事：
* 确定 skb->pkt_type ，即包在链路层的类型，它可以有多个参数：
    PACKET_HOST       //当前主机的包
	PACKET_BROADCAST  //广播包
	PACKET_MULTICAST  //多播包
	PACKET_OTHERHOST  //其他主机的包
* 确定下一层协议的类型并返回，在以太网数据包中，这个值通常是 ETH_P_IP，表示下一层协议是 IPv4 协议，对于不同的链路层以及 IP 层协议，这个值也会随之不同，关于 protocol 的定义，可以在 include/uapi/linux/if_ether.h 看到所有的定义。  

这两个字段的值将会决定该数据包在下一层接口的路由方式，或者是丢弃，或者是交给 ip 处理程序。  

对于开发者而言，事实上不需要考虑 eth_type_trans 的实现细节，只需要简单地调用下面的接口即可：
```
skb->protocol = eth_type_trans(skb,netdev);
```

至于包的校验以及链路层的其它操作，都由系统的下一层接口自动完成，这也是网络子系统驱动程序协议无关的实现特点。  


### 提交数据
处理完数据之后，就需要将数据提交到上层，它就是一个简单的接口：

```
int netif_rx(struct sk_buff *skb)
```

该接口会将当前创建并处理完成的 sk buff 传递到下一层协议处理，对于网络协议的处理就到此为止了。  


### 其他操作
上述的所有操作都是在中断中处理的，但是在某些情况下，需要在数据处理的同时处理一些耗时的任务，不能在中断中直接执行，这就需要使用到下半部的接口，最常用的就是工作队列，将一些费时的任务交给工作队列延后执行。  






### 驱动程序框架小结
从整体上看来，以太网的网卡驱动程序并不复杂，和其他驱动程序一样，都是做填空题，填充结构体，然后注册到系统，在系统使用时就会使用到我们的一些参数，或者调用到一些设置的回调函数以实现功能。  

简单的网卡驱动程序可以参考 dm9000 的驱动实现，它的源码地址为：net/ethernet/davicom/dm9000.c，实现并不复杂，作为一个标准实现来研究是可以的。  

接下来我们对整个网卡驱动程序做一个小结：
* 在网卡的 probe 函数中调用 alloc_etherdev 函数申请一个网卡结构。  
* 填充该网卡结构体，最主要的部分是填充 netdev_ops 成员，其中 ndo_start_xmit 回调函数将会在网卡发送数据时调用。  
* 在网卡的 open 回调函数中注册网卡中断处理程序，在收发数据时都会通过中断来实现。
    
* 调用 register_netdev 函数将填充完成的网卡注册到系统。  

接收的具体实现：
* 调用 netdev_alloc_skb 申请一个 skb，并使用接收到的数据填充它。
* 调用 eth_type_trans 获取 protocol。
* 调用 netif_rx 将数据提交到上层处理。

发送的实现：

* ndo_start_xmit 的实现：当上层发送数据时，将会调用 ndo_start_xmit 函数，在该函数中负责将 skb 中的数据拷贝出来，并通过操作网卡发出。 
* 释放当前的 skb。



