# cpu 拓扑结构
在研究 cfs 调度器的时候,碰到一个难缠的问题:进程迁移,进程的迁移总是发生在多核之间,在之前对其它内核组件的分析中,比如内核中的锁,往往是把"多核"或者 SMP 当成一个黑盒子,所讨论的都仅仅是需要多考虑一种多核的并发情况.   

但是,在分析进程的迁移时,再把多核架构对应的软件处理当成黑盒子就不合适了,因为多核系统的内部架构将直接影响到进程在核心上的调度行为.  


## 硬件上的多核架构
在 linux 内核中,软件架构总是基于硬件的抽象,因此,想要研究内核中的软件实现,第一步需要做的就是先弄清楚硬件上是怎样的.  

对于 cpu/多核 这些概念是硬件强相关的,不同的体系架构自然是天差地别,最常见的 x86 架构几乎统治了个人电脑和服务器两个领域,对于这两个领域,一个要求响应速度,一个要求吞吐量,因此对于基于 x86 的平台而言,高主频,超标量,超线程,多级流水线这些都是常见配置,因为这些东西可以实实在在地提升一台主机的程序执行速率.  

另一方面,移动端的兴起让主打低功耗的 arm 架构获得市场的青睐,就目前而言,arm 的特性在于 cpu 的程序执行效率和功耗之间的平衡,不需要太高的主频,cpu 也不会集成大量的运算器件,同时精简指令集也可以简化硬件的设计,以至于 arm 和 x86 在不同的领域各自为王.但是,目前已经在移动领域站稳脚跟的 arm 也不再满足于现状,开始向服务器领域进军,至于未来会怎样,time will tell.  

尽管不同的架构针对不同的领域有不同的硬件设计,但是对于效率的追求总是不变的,在主频的提升遇到瓶颈之后,各个架构都不约而同地转向了多核架构的研究,而一旦打开了多核设计这个潘多拉魔盒,事情就变得一发不可收拾起来.  

在多核设计中,不得不提的另一个概念是缓存技术,缓存是很早之前就存在的一种设计思想,比如仓储的设计,被应用在计算机中,从一台完整电脑的角度来看,cpu 内部寄存器是 cpu cache 的缓存,cpu cache 是内存的缓存,内存是磁盘的缓存...  

不得不说,缓存和多核这两种技术对 CPU 性能提升是巨大的,对于硬件设计人员来说这是两把利器，俗话说，死道友不死贫道，硬件设计人员圆满地完成 KPI 的同时，软件工程师面对越来越复杂的硬件所带来的复杂性，发际线越来越高，毕竟在已有硬件升级的前提下，软件工程师的工作就是修改软件，重新适配硬件，没有合适的软件，硬件只是一堆带电的元器件，而需要发挥 多核+多级缓存 的性能优势，软件工程师需要十分相当的功底。  

## 流水线
一个基本的 cpu 中通常包含 总线、寄存器组、ALU 以及可选的 MMU、浮点计算器、协处理器等器件，这些器件完成 CPU 的基本工作，或是控制，或是运算，其本质都是对于数据的处理，每个 CPU 内部器件通力合作，在一个指令周期内完成一条具体的指令，这条指令可能是更新内存，也可能是做逻辑运算。   

可以想到，在这种情况下，影响指令执行效率的因素就是 CPU 的指令周期时间，也就是常说的 cpu 主频，cpu 内所有的元器件都根据 cpu 的 clock 进行同步，提高 cpu 的主频自然而然成了提升 cpu 的一个主要途径，但是执行一条指令需要经过取出指令、译码器进行译码、再将具体指令送到 ALU 或者寄存器其它部件等多个步骤，而 cpu 的一个 clock 至少要等到一条完整的指令操作完成，才能发起下一个 clock,如果这个操作需要 1us,那么 cpu 的主频就不能高于 1MHz，否则就得不到正确的结果.在这种情况下，主频的提升上限受到硬件的限制。  

流水线技术就是在这种环境下诞生的,既然一条完整的指令操作需要的时长限制了主频,那么就从硬件上将这条指令切分开来,比如一条完整的指令通常需要取指,译码,执行,访存,回写这几个步骤,那么就从硬件上将这五个步骤分开,这就是经典的五级流水线的结构.它的工作方式参考下图(TODO).  

相较于非流水线而言,流水线的引入带来了两个巨大的优势:
1.在非流水线模式下,在执行一条完整的指令时,通常有相当一部分硬件是空置的,也就是说当指令在取指阶段时,其它的功能硬件就处于空转的状态,而流水线的引入极大地提升了硬件资源的利用率,从图中可以看出,在理想状态下,并行地执行三条指令只需要 7 个周期,如果不使用流水线技术,执行这三条指令需要相对于当前 15 个周期的时间,而流水线的引入所增加的硬件成本只是对原本电路进行部分重排,同时增加一些流水线寄存器以保存中间状态,这些成本相对于性能的提升而言不值一提.
2.流水线可以提高主频,正如上图所示,采用五级流水线的结构,时钟周期设置为 5 个步骤中耗时最长的操作时间,这不难理解,CPU 的一个时钟周期必须保证所有部件都能执行完成.在理想状态下,也就是上述五个部件耗时一致的情况下,不采用流水线的设计中执行一条指令耗时是采用流水线技术的 5 倍,因此 CPU 主频也就要降低 5 倍.  

流水线技术的引入给提升主频打开了一扇新的大门,从理论上来说,只要把一条指令分得足够细,比如将上述的 5 级流水线中的 5 个步骤再次细分,分成 10 级流水线,那么理论上主频就可以再提升一倍(这种扩充方式所产生的流水线结构也被称为超级流水线),在奔腾 4 上就曾经实现过最多的 31 级流水线,当然主频也非常高,但是,流水线真的是越多越好吗?答案是否定的.  

随着流水线的增加,频率的提升慢慢地出现了边际效应,一方面,增加流水线需要增加流水线寄存器,在流水线级数较少的时候,流水线寄存器所带来的延迟(这里的延迟可以理解为硬件的执行时间)不值一提,但是随着流水线的增加,流水线寄存器的延迟占比越来越大,但是流水线寄存器的延迟原本并不属于指令的有效执行时间,它是流水线技术引入的中间环节,对指令的执行而言属于无效操作.  

比如对于一个基本的 5 级流水线,每一级部件的硬件延迟为 200ps,流水线寄存器延迟为 20ps,那么 cpu 指令周期可设置为 220ps,执行一条指令的时间为 1100ps,如果采用 10 级流水线,每一级部件的硬件延迟变为 100ps,流水线寄存器延迟依旧为 20ps,cpu 指令周期可设置为 120 ps,那么执行一条指令的时间变成了 1200ps,也就是说,流水线越长,单条指令的执行时间越长,cpu 执行的有效时间占比越小,而流水线拉长所能提升频率也逐渐减小,并非是线性的.因此,拉长流水线提升主频这种方式是有尽头的.  

另外,增加流水线意味着更多地让 cpu 中的部件并行地活动起来,这必然带来功耗上的增加,因此,当频率越来越高的时候,功耗和散热就成了 cpu 的一个不得不面临的巨大难题.  

另一方面,上面针对流水线的讨论都是基于理想状态下,每一条指令按部就班地执行按照 clock 执行,实际情况并不是理想的,比如当执行跳转指令时,程序会跳到另一个地址执行另一部分程序,但是硬件并不知道下一条指令将会跳转到哪个分支,这种情况下很可能在跳转之后所有的流水线中保存的执行结果都需要重新刷新和填充,因为流水线中不存在有效的数据,cpu 不得不停顿下来等待流水线的填充,而流水线越长,重刷流水线的代价越大.尽管现代 cpu 的分支预测功能已经可以达到 90% 以上的准确率,但是过长流水线带来的流水线停顿依旧是不可忽视的.  

鉴于上述原因,在现代的处理器中,流水线的长度通常被实现为 13 级左右,当然,低端处理器只会更少. 

## 超标量流水线
加深流水线是提升吞吐量的一种方式,与之相对的另一个方向就是拓宽流水线,而拓宽流水线这个方案就被称为超标量流水线,相对应的,传统流水线被称为标量流水线.  

标量流水线表示多条指令处于不同的阶段并行执行,但是每一个处理阶段只能处理一条指令,这是硬件决定的,比如译码部件只有一个,一个周期只能有一条指令处于译码状态,超标量流水线直接增加相应的硬件部件,这样就有了两条可以同时工作的流水线了,这种结构也被成为双发射结构,相对应的也存在三/四发射结构处理器,理论上就可以并行执行更多的指令了.   

尽管超标量流水线横向拓宽流水线,但是它增加硬件的方式并不是想象中的成套增加硬件部件,比如对于取指而言,不一定需要增加取指部件,可能是拓宽了总线宽度,比如设计 128 位的取指总线,一次就可以取 4 条指令(32位系统),又比如在流水线中,CPU 主频取决于流水线中最慢的部件,而快一些的部件完全可以分段执行,当然,实现超标量时硬件的大量增加是必然的.  

理想是美好的,现实总是比较残酷,理想状态下,每条指令都是相互独立的,但实际上这根本不可能,大部分指令都是相互关联的,很可能出现下一条指令依赖于上一条指令结果的情况从而引起流水线的冲突(比如上一条指令没有写回,当前指令已经到执行阶段),在数据运算或者转移指令中比较常见,又或者多条指令的不同流水线阶段使用到同样的硬件结构,这些冲突通常可以通过硬件解决一部分,但是超标量的引入将这种问题进一步复杂化,由此 cpu 引入了乱序执行的概念,既然多条相关联的指令会造成流水线上的冲突,那么 cpu 就将指令的顺序重排,让与当前指令执行相冲突的指令延后执行,将不相关的指令提前执行,然后从执行上来说是乱序的,但是只要保证执行结果的提交是符合程序逻辑即可.  


## 超线程
在 CPU 中,出于性能考虑,引入了流水线,超标量技术,尤其是对于超标量的引入,同时也增加了大量的硬件资源,当然,在理想状态下,这些硬件资源都应该被合理利用,但是由于各种各样的问题,这些资源经常被闲置,为了把这些资源给充分地利用起来,干脆使用这些资源组合成一个新的逻辑 CPU 核,这也就是超线程的由来,实际的实现中,还涉及到一些其它硬件上的修改.  

线程这个概念通常被用在软件中,表示软件商单独的一个执行流,多线程可能分时运行在单个 CPU 上,也可能同时运行在多个 CPU 上.超线程的概念明显是硬件上的,它同样表示一个单独的执行流,硬件上一个单独的执行流其实就可以看成是一个单独的 CPU 核了,它有独立的 pc 指针,各类寄存器和执行单元,只是这个额外的 cpu 核大部分资源是由闲置的资源组建的,并不完全独立存在,这也是为什么称之为"逻辑核",而不是真实的物理核.  

超标量和超线程这两者乍一看是非常像的,都是为了实现同时执行多条指令,但是它们有本质区别,超标量结构又被成为多发射结构,意味着它可以一次取多条指令执行,但是这多条指令是同属于一个程序执行流的,而超线程则是实实在在地模拟出了一个 CPU 核,它完全可以运行另一个程序或者执行流.  


## SMP 多核
随着硬件的发展，CPU 这个概念变得越来越模糊，对于普通用户而言，CPU 就是那块方方正正、闪着金属光芒的芯片，而从软件层面来说，我们通常又把 CPU 当成是一个程序执行调度单元，比如通常说的某个进程在 CPU0 或者 CPU1 上执行，很明显，肉眼可见的物理 CPU 和软件中的 CPU 并不是同一个概念。   

一个物理 CPU 中通常包含多个核，对应 core 这个概念，每个核对应独立的执行程序的部件，包括寄存器组、ALU、MMU 等器件，这些 core 拥有独立的 L1 cache，共享的 L3 cache，而 L2 cache 是可选的。  

如果 CPU 支持超线程，那么 CPU 中的核就不是最基本的程序执行调度单元，而是 core 中存在的两个或多个硬件线程。在 linux 内核中，CPU 这个概念始终指的是程序的执行调度单元，又称为逻辑 CPU，因为它并不一定指代某个物理上独立的 CPU，如果支持超线程，那么 CPU 就是对硬件线程的抽象，否则就是对 core 的抽象。当然，这里讨论的是多核 CPU 的情况，如果是单核处理器，物理CPU = core = 逻辑 CPU。  

### cache
CPU 存储的结构为：CPU寄存器 -> L1 cache -> L2 cache -> L3 cache -> 内存，从左到右，速度越来越慢，成本越来越低，而容量越来越大，使用 cache 的意义在于：将软件常用的数据缓存起来，下次使用时就不再需要从最慢的内存中取，而是直接从最近且最快的 cache 中获得，这样可以大大加速内存的访问。  

其具体的做法是：当程序需要访问一个数据(或指令)时，先会检查当前数据是否存在于某一级 cache 中(cache命中)，如果不存在(cache miss)，会将数据以及其附近地址的数据从内存中加载到各级 cache 中，而程序的执行很可能会再次用到该数据或者该数据附近的数据，从软件上来看，这并不难理解，我们所编写的函数通常都具有局部性的特征，函数中所定义的变量以及对变量的处理代码都集中在一个范围内，同样的，对于结构体的定义也是这样，通常一个数据结构中相邻的数据成员很可能被同时使用到，还有就是做循环处理时，基于这些程序局部性的特征，cache 这种缓存数据块的实现对性能提升有巨大的贡献。  

cache 的引入并不是免费的提升，一方面它提高了软硬件设计的复杂度，当然这个可以接受，另一方面，在多核系统中，cache 一致性是一个头疼的问题，通常 L1 和 L2 都是每个核自带的 cache，多核之间并不同步，但是对于一个全局数据而言，core1 和 core2 同时将它加载到了 cache 中，如果 core1 对它进行了修改，那么 core2 的 cache 中所保存的数据就会被 invalidate，core2 中再处理该全局数据时就必须重新从内存中一级一级地加载到 cache 中，这个操作由硬件完成，但是通常需要从软件层面来尽量避免这类操作。 

## NUMA 架构
CPU 中每多一个核,相当于多出一个独立的程序执行调度单元,直接从一个人做事变成两个人做事,理想状态下,相当于成倍地增加系统性能,硬件设计人员自然热衷于使用多核以及多 CPU 的架构.  

但是,核心数的增加并不等于性能的线性增长,为了内存访问的速率,一个物理 CPU 上的多核通常是共享同一个 L3 cache,而多个物理 CPU 之间共享主存,既然是共享,那么必然会产生竞争行为,同一个共享区域内请求单位越多,势必造成冲突的加剧,而这种情况下所带来的问题是,大量的时间会浪费在竞争的处理上(等待资源).  

因此,这种情况下,一个物理 CPU 中核心数量必然是有限的,系统中的物理 CPU 数量也会受到限制.问题是,如果多核或者多 CPU 之间不共享 cache 和内存呢,是不是就不存在这个问题了?不共享内存的方式确实是解决了竞争问题,但是各个核(物理CPU)却成了独立的个体,一起做事变成了各自做各自的事,核间的通信成本非常高,如果一开始任务分配不均衡,后续的负载均衡成本将会非常高,而系统中的负载均衡操作是非常频繁的.  

好不容易找到一个提升性能的方式,就这么轻易地遭遇瓶颈,硬件设计人员自然不甘心,有没有什么办法能在一个处理器上集成多个物理 CPU 呢?这时候 cache 的概念再次发挥了作用,也就是为每个物理 CPU 增加一层 cache,这层 cache 就是本地内存,这时候一个物理处理器的内存结构变成了:CPU寄存器->L1 cache->L2 cache->L3 cache->本地内存->共享内存,这种新的结构叫做 NUMA 结构,即非一致性内存访问结构,每个核心访问本地内存,而每个物理 CPU 被称为 node.     

这种情况下,就可以继续增加物理 CPU,只要尽量避免对共享内存的访问,就可以解决冲突问题,这其实不算是什么新的方法,只是老方法的延伸,你也可以将这种架构理解为:一个系统内,CPU/核心数量由于共享内存的竞争达到上限,NUMA 结构就是将多个这样的系统进行组合,再增加一个共享的内存,形成一个更大的系统. 


参考:
<cosera 计算机组成课程-陆俊林>


